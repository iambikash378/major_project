{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "from torch.nn.functional import relu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dice_loss(y_pred, y_true, smooth = 1e-6):\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_true = y_true.flatten()\n",
    "\n",
    "    intersection = (y_pred * y_true).sum()\n",
    "    dice = (2.0 * intersection + smooth) / (y_pred.sum() + y_true.sum() + smooth)\n",
    "\n",
    "    return 1-dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(y_pred, y_true):\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    y_pred = (y_pred > 0.5).float()\n",
    "    intersection = (y_pred * y_true).sum()\n",
    "    return (2.0 * intersection + 1e-6) / (y_pred.sum() + y_true.sum() + 1e-6) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class hrgldd_dataset(Dataset): \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "      \n",
    "    def __getitem__(self, index):\n",
    "        img = self.x[index]\n",
    "        label = self.y[index]\n",
    "\n",
    "        img = torch.from_numpy(img).float()\n",
    "        label = torch.from_numpy(label).float()\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(out_channels, out_channels,kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownSample, self).__init__()\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        down = self.conv(x)\n",
    "        p = self.pool(down)\n",
    "        return down, p\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super(UpSample,self).__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels//2,\n",
    "                                     kernel_size = 2,\n",
    "                                     stride = 2)\n",
    "        self.conv = DoubleConv(in_channels,out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x1,x2],1)\n",
    "        x2 = self.conv(x)\n",
    "        return x2\n",
    "    \n",
    "    \n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.down_conv_1 = DownSample(4, 64)\n",
    "        self.down_conv_2 = DownSample(64, 128)\n",
    "        self.down_conv_3 = DownSample(128, 256) \n",
    "        self.down_conv_4 = DownSample(256, 512)\n",
    "\n",
    "        self.bottleneck = DoubleConv(512, 1024)\n",
    "\n",
    "        self.up_conv_1 = UpSample(1024,512)\n",
    "        self.up_conv_2 = UpSample(512,256)\n",
    "        self.up_conv_3 = UpSample(256,128)\n",
    "        self.up_conv_4 = UpSample(128,64)\n",
    "\n",
    "        self.out = nn.Conv2d(in_channels=64, out_channels = 1,\n",
    "                             kernel_size = 3\n",
    "                             )\n",
    "\n",
    "    def forward(self,x):\n",
    "        down1, p1 = self.down_conv_1(x)\n",
    "        down2, p2 = self.down_conv_2(p1)\n",
    "        down3, p3 = self.down_conv_3(p2)\n",
    "        down4, p4 = self.down_conv_4(p3)\n",
    "\n",
    "        b = self.bottleneck(p4)\n",
    "\n",
    "        up_1 = self.up_conv_1(b, down4)\n",
    "        up_2 = self.up_conv_2(up_1,down3)\n",
    "        up_3 = self.up_conv_3(up_2, down2)\n",
    "        up_4 = self.up_conv_4(up_3, down1)\n",
    "\n",
    "        op = self.out(up_4)\n",
    "\n",
    "        return op\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    LEARNING_RATE = 5e-4\n",
    "    BATCH_SIZE = 16\n",
    "    EPOCHS = 1\n",
    "    DATA_PATH = \"\"\n",
    "    MODEL_SAVE_PATH = \"\"\n",
    "\n",
    "\n",
    "    path_to_testX = ''\n",
    "    path_to_testY = ''\n",
    "    path_to_trainX = ''\n",
    "    path_to_trainY = ''\n",
    "    path_to_valX = ''\n",
    "    path_to_valY = ''\n",
    "\n",
    "    data_testY = np.load(path_to_testY)\n",
    "    data_testX = np.load(path_to_testX)\n",
    "    data_trainX = np.load(path_to_trainX)\n",
    "    data_trainY = np.load(path_to_trainY)\n",
    "    data_valX = np.load(path_to_valX)\n",
    "    data_valY = np.load(path_to_valY)\n",
    "\n",
    "    train_dataset = hrgldd_dataset(data_trainX, data_trainY)\n",
    "    val_dataset = hrgldd_dataset(data_valX, data_valY)\n",
    "    test_dataset = hrgldd_dataset(data_testX, data_testY)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    train_dataloader = DataLoader(dataset = train_dataset,\n",
    "                                  batch_size = BATCH_SIZE,\n",
    "                                  shuffle = True)\n",
    "    val_dataloader = DataLoader(dataset = val_dataset,\n",
    "                                batch_size = BATCH_SIZE,\n",
    "                                shuffle = True)\n",
    "\n",
    "    model = UNet().to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr = LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.1, patience = 3 , verbose = True)\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        train_running_loss = 0\n",
    "        model.train()\n",
    "        for index, x_y in enumerate(tqdm(train_dataloader)):\n",
    "            img = x_y[0].float().permute(0,3,1,2).to(device)\n",
    "            mask = x_y[1].float().permute(0,3,1,2).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(img) \n",
    "            loss = dice_loss(outputs, mask)\n",
    "            loss.backward() #Find Gradients by Backward Pass\n",
    "            optimizer.step() #Update the weights\n",
    "\n",
    "            train_running_loss += loss.item()\n",
    "\n",
    "        train_loss = train_running_loss / len(train_dataloader)\n",
    "\n",
    " # --------------- Validation Part ------------------------ #\n",
    "\n",
    "        model.eval()\n",
    "        val_running_loss = 0\n",
    "        val_dice = 0\n",
    "        with torch.no_grad():\n",
    "            for index, x_y in enumerate(tqdm(val_dataloader)):\n",
    "                img = x_y[0].float().permute(0,3,1,2).to(device)\n",
    "                mask = x_y[1].float().permute(0,3,1,2).to(device)\n",
    "\n",
    "                y_pred = model(img)\n",
    "                loss = dice_loss(y_pred, mask)\n",
    "                val_running_loss += loss.item()\n",
    "\n",
    "                val_dice += dice_score(y_pred, mask).item()\n",
    "            \n",
    "            val_loss = val_running_loss / len(val_dataloader)\n",
    "            val_dice = val_dice / len(val_dataloader)\n",
    "        \n",
    "        print(\"--\" * 30)\n",
    "        print(f\"Train Loss EPOCH {epoch +1}: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss EPOCH {epoch +1} : {val_loss:.4f}\")\n",
    "        print(f\"Val Dice Score EPOCH {epoch + 1} : {val_dice:.4f}\")\n",
    "        print(f\"Current Learning Rate : {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "            print(f\"Saved best model with val loss : {val_loss : .4f}\")\n",
    "\n",
    "        scheduler.step(val_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
