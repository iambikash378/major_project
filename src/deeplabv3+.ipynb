{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c842d386a9a48e9a0ec416345ef119f": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_aea75aa8486d4d258521a1c2a0261eda",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[32m⠋\u001b[0m Waiting for authorization\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠋</span> Waiting for authorization\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "aea75aa8486d4d258521a1c2a0261eda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow dagshub -qqq"
      ],
      "metadata": {
        "id": "INWqmvGuLTsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import dagshub\n",
        "\n",
        "dagshub.init(\n",
        "    repo_name=\"mlflow_major\",\n",
        "    repo_owner=\"iambikash378\",\n",
        "    mlflow=True\n",
        ")\n",
        "\n",
        "mlflow.set_tracking_uri(f\"https://dagshub.com/iambikash378/mlflow_major.mlflow\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "0c842d386a9a48e9a0ec416345ef119f",
            "aea75aa8486d4d258521a1c2a0261eda"
          ]
        },
        "id": "XZNqMr9YLXA_",
        "outputId": "5cf36641-9180-4aaf-f7eb-8e9cb53200b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Open the following link in your browser to authorize the client:\n",
            "https://dagshub.com/login/oauth/authorize?state=d0df08b0-1a42-4b92-9b83-83b75c1a9232&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=bbb40aa79807a85e67ed84ed59e5ce6e393e1b6b42483d20a4604442802d4e41\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c842d386a9a48e9a0ec416345ef119f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Accessing as iambikash378\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as iambikash378\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"iambikash378/mlflow_major\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"iambikash378/mlflow_major\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Repository iambikash378/mlflow_major initialized!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository iambikash378/mlflow_major initialized!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACHoUJuuBHY-",
        "outputId": "4190829b-41ec-4760-9f4b-8445fd7c908f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U4w3YN-0BRUg",
        "outputId": "f8aeec3f-7f3f-477a-8c45-3bc2f12de753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/major_proj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8AhU5MKBhw3",
        "outputId": "8660c982-d3ad-4a85-f0b0-fd2b1e5835af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1Ksve6Nua5d8mXhXEQl0u5pVhxS2-eWv5/major_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U segmentation-models-pytorch"
      ],
      "metadata": {
        "id": "sRrXu1zmBpiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_pytorch as smp"
      ],
      "metadata": {
        "id": "nz-6KhkDBvd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "4Mwr-nWWvcd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "model = smp.DeepLabV3Plus(\n",
        "    encoder_name=\"resnet34\",\n",
        "    encoder_depth = 5,\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels= 4,\n",
        "    classes= 1,\n",
        ")\n",
        "model= model.to(device)"
      ],
      "metadata": {
        "id": "5NFreAs9CWtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5555e3-5418-4151-b4e0-e097bef4672c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
            "100%|██████████| 83.3M/83.3M [00:01<00:00, 83.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from segmentation_models_pytorch.encoders import get_preprocessing_fn"
      ],
      "metadata": {
        "id": "rurmxEPwC6N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "N1sdejUab4Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "# # Define the augmentation pipeline\n",
        "# transform = A.Compose([\n",
        "#     A.HorizontalFlip(p=0.5),   # Horizontal flip\n",
        "#     A.VerticalFlip(p=0.5),     # Vertical flip (if you want both)\n",
        "#     A.RandomRotate90(p=0.5),   # Random 90-degree rotation\n",
        "#     A.RandomCrop(width=128, height=128, p=1.0),  # Crop image\n",
        "#     A.Rotate(limit=45, p=1.0),\n",
        "# ])\n",
        "\n",
        "class hrgldd_dataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = self.x[index]\n",
        "        label = self.y[index]\n",
        "\n",
        "        img = torch.from_numpy(img).float().permute(2,0,1)\n",
        "        label = torch.from_numpy(label).float().permute(2,0,1)\n",
        "\n",
        "        return img, label\n"
      ],
      "metadata": {
        "id": "4M2aMXXLDo9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ffa4df4-f52a-4d8f-fc2f-e60f519768c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.5' (you have '2.0.4'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "path_to_testX = '/content/drive/MyDrive/major_proj/HR-GLDD/testX.npy'\n",
        "path_to_testY = '/content/drive/MyDrive/major_proj/HR-GLDD/testY.npy'\n",
        "\n",
        "path_to_trainX = '/content/drive/MyDrive/major_proj/HR-GLDD/jointX.npy'\n",
        "path_to_trainY = '/content/drive/MyDrive/major_proj/HR-GLDD/jointY.npy'\n",
        "\n",
        "path_to_valX = '/content/drive/MyDrive/major_proj/HR-GLDD/valX.npy'\n",
        "path_to_valY = '/content/drive/MyDrive/major_proj/HR-GLDD/valY.npy'\n",
        "\n",
        "data_testY = np.load(path_to_testY)\n",
        "data_testX = np.load(path_to_testX)\n",
        "\n",
        "data_trainY = np.load(path_to_trainY)\n",
        "data_trainX = np.load(path_to_trainX)\n",
        "\n",
        "data_valY = np.load(path_to_valY)\n",
        "data_valX = np.load(path_to_valX)\n",
        "\n",
        "train_dataset = hrgldd_dataset(data_trainX, data_trainY)\n",
        "val_dataset = hrgldd_dataset(data_valX, data_valY)\n",
        "test_dataset = hrgldd_dataset(data_testX, data_testY)"
      ],
      "metadata": {
        "id": "CKdc9e4pD9L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 5e-4\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 500\n",
        "PATIENCE = 20\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/major_proj/trained_models/deeplabv3plus.pth\"\n",
        "THRESHOLD = 0.5\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                               batch_size=BATCH_SIZE,\n",
        "                               shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=True)\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                               batch_size=BATCH_SIZE,\n",
        "                               shuffle=True)"
      ],
      "metadata": {
        "id": "ZWq8cIsjD6rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_input = get_preprocessing_fn('resnet18', pretrained='imagenet')"
      ],
      "metadata": {
        "id": "Zke0RwufDDRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from segmentation_models_pytorch import losses\n",
        "from segmentation_models_pytorch.losses.constants import BINARY_MODE\n",
        "loss_fn = losses.FocalLoss(mode = BINARY_MODE)"
      ],
      "metadata": {
        "id": "X6ChPT_yDchW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)"
      ],
      "metadata": {
        "id": "gPjtMgeWHtQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.end_run()"
      ],
      "metadata": {
        "id": "y_LHWZ5k3Pk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h0Av265aKdSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "counter = 0\n",
        "\n",
        "with mlflow.start_run():\n",
        "  mlflow.log_params(\n",
        "      {\n",
        "          \"initial_learning_rate\": LEARNING_RATE,\n",
        "          \"batch_size\": BATCH_SIZE,\n",
        "          \"model_arch\": 'DeepLabV3Plus',\n",
        "          \"encoder_name\": 'resnet34',\n",
        "          \"encoder_depth\": 5,\n",
        "          \"encoder_weights\": 'imagenet',\n",
        "          \"loss_function\": loss_fn,\n",
        "          \"epochs\": EPOCHS,\n",
        "          \"patience\": PATIENCE,\n",
        "          \"optimizer\": type(optimizer).__name__,\n",
        "          \"threshold\" : THRESHOLD,\n",
        "          \"remarks\" : \"augmented\"\n",
        "      }\n",
        "  )\n",
        "  for epoch in range(EPOCHS):\n",
        "    train_running_loss = 0\n",
        "    model.train()\n",
        "    for images, gt_masks in train_dataloader:\n",
        "\n",
        "        images = images.to(device)\n",
        "        gt_masks = gt_masks.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predicted_mask = model(images)\n",
        "        loss = loss_fn(predicted_mask, gt_masks)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_running_loss += loss.item()\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "    train_loss = train_running_loss / len(train_dataloader)\n",
        "    print(f\"\\nEpoch: {epoch+1}/{EPOCHS}, Train Loss: {train_loss}\")\n",
        "    mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
        "\n",
        "    #############################################################\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0\n",
        "    #val_dice = 0\n",
        "    val_accuracy = 0\n",
        "    val_precision = 0\n",
        "    val_recall = 0\n",
        "    val_f1 = 0\n",
        "    with torch.no_grad():\n",
        "        for images, gt_masks in val_dataloader:\n",
        "\n",
        "            images = images.to(device)\n",
        "            gt_masks = gt_masks.to(device)\n",
        "\n",
        "            y_pred = model(images)\n",
        "            val_loss = loss_fn(y_pred, gt_masks)\n",
        "            val_running_loss += val_loss.item()\n",
        "\n",
        "\n",
        "            y_pred_binary = (torch.sigmoid(y_pred) > THRESHOLD).float()\n",
        "            mask_binary = (gt_masks > 0.5).float()\n",
        "            y_pred_flat = y_pred_binary.view(-1).cpu().numpy()\n",
        "            mask_flat = mask_binary.view(-1).cpu().numpy()\n",
        "\n",
        "            val_accuracy += accuracy_score(mask_flat, y_pred_flat)\n",
        "            val_precision += precision_score(mask_flat, y_pred_flat, zero_division=0)\n",
        "            val_recall += recall_score(mask_flat, y_pred_flat, zero_division=0)\n",
        "            val_f1 += f1_score(mask_flat, y_pred_flat, zero_division=0)\n",
        "\n",
        "        val_loss = val_running_loss / len(val_dataloader)\n",
        "        #val_loss_list.append(val_loss)\n",
        "        #val_dice = val_dice / len(val_dataloader)\n",
        "        val_accuracy = val_accuracy / len(val_dataloader)\n",
        "        val_precision = val_precision / len(val_dataloader)\n",
        "        val_recall = val_recall / len(val_dataloader)\n",
        "        val_f1 = val_f1 / len(val_dataloader)\n",
        "\n",
        "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
        "        mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n",
        "        mlflow.log_metric(\"val_precision\", val_precision, step=epoch)\n",
        "        mlflow.log_metric(\"val_recall\", val_recall, step=epoch)\n",
        "        mlflow.log_metric(\"val_f1\", val_f1, step=epoch)\n",
        "\n",
        "    print(\"--\" * 30)\n",
        "    print(f\"Train Loss EPOCH {epoch + 1}: {train_loss:.4f}\")\n",
        "    print(f\"Val Loss EPOCH {epoch + 1} : {val_loss:.4f}\")\n",
        "    #print(f\"Val Dice Score EPOCH {epoch + 1} : {val_dice:.4f}\")\n",
        "    print(f\"Val Precision EPOCH {epoch + 1}: {val_precision:.4f}\")\n",
        "    print(f\"Val Recall EPOCH {epoch + 1}: {val_recall:.4f}\")\n",
        "    print(f\"Val F1 Score EPOCH {epoch + 1}: {val_f1:.4f}\")\n",
        "    print(f\"Current Learning Rate : {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        mlflow.log_artifact(MODEL_SAVE_PATH)\n",
        "        print(f\"Saved best model with val loss : {val_loss:.4f}\")\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"No improvement in validation loss for {counter} epochs.\")\n",
        "\n",
        "    if counter >= PATIENCE:\n",
        "        print(f\"Early stopping triggered after {PATIENCE} epochs without improvement.\")\n",
        "        break\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n"
      ],
      "metadata": {
        "id": "SB5hXyxHDPEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xFSOFzX5v-Fh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}