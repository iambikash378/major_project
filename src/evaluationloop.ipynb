{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "e1zhrkJVywr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "B6J7J5TZOhNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "ePMWzC8HOeOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class hrgldd_dataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = self.x[index]\n",
        "        label = self.y[index]\n",
        "\n",
        "        img = torch.from_numpy(img).float().permute(2,0,1)\n",
        "        label = torch.from_numpy(label).float().permute(2,0,1)\n",
        "\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "bfEbqrZSyu7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_testX = '/content/drive/MyDrive/major_proj/HR-GLDD/testX.npy'\n",
        "path_to_testY = '/content/drive/MyDrive/major_proj/HR-GLDD/testY.npy'\n",
        "\n",
        "data_testY = np.load(path_to_testY)\n",
        "data_testX = np.load(path_to_testX)"
      ],
      "metadata": {
        "id": "MswxikRMzk0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dice_loss(y_pred, y_true, smooth = 1e-6):\n",
        "    y_pred = y_pred.float().view(-1)\n",
        "    y_true = y_true.float().view(-1)\n",
        "\n",
        "    intersection = (y_pred * y_true).sum()\n",
        "    union = y_pred.sum()+y_true.sum()\n",
        "    if ((2.0*intersection)+smooth) > (union+smooth):\n",
        "        print(\"Error !\")\n",
        "    dice = ((2.0 * intersection) + smooth) / (union + smooth)\n",
        "\n",
        "    return 1-dice"
      ],
      "metadata": {
        "id": "6GFbNTZftkdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv,self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Conv2d(out_channels, out_channels,kernel_size = 3, padding = 1),\n",
        "            nn.ReLU(inplace = True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class DownSample(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DownSample, self).__init__()\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "    def forward(self,x):\n",
        "        down = self.conv(x)\n",
        "        p = self.pool(down)\n",
        "        return down, p\n",
        "\n",
        "\n",
        "class UpSample(nn.Module):\n",
        "\n",
        "    def __init__(self,in_channels,out_channels):\n",
        "        super(UpSample,self).__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_channels, in_channels//2,\n",
        "                                     kernel_size = 2,\n",
        "                                     stride = 2)\n",
        "        self.conv = DoubleConv(in_channels,out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        x = torch.cat([x1,x2],dim = 1)\n",
        "        x2 = self.conv(x)\n",
        "        return x2\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.down_conv_1 = DownSample(in_channels, 64)\n",
        "        self.down_conv_2 = DownSample(64, 128)\n",
        "        self.down_conv_3 = DownSample(128, 256)\n",
        "        self.down_conv_4 = DownSample(256, 512)\n",
        "\n",
        "        self.bottleneck = DoubleConv(512, 1024)\n",
        "\n",
        "        self.up_conv_1 = UpSample(1024,512)\n",
        "        self.up_conv_2 = UpSample(512,256)\n",
        "        self.up_conv_3 = UpSample(256,128)\n",
        "        self.up_conv_4 = UpSample(128,64)\n",
        "\n",
        "        self.out = nn.Conv2d(in_channels=64, out_channels = 1,\n",
        "                             kernel_size = 3, padding = 1\n",
        "                             )\n",
        "\n",
        "    def forward(self,x):\n",
        "        #print(f\"Input Shape : {x.shape}\")\n",
        "\n",
        "        down1, p1 = self.down_conv_1(x)\n",
        "        #print(f\"Shape after doubl_conv_1_only : {down1.shape}\")\n",
        "        #print(f\"Shape after down_conv_1 : {p1.shape}\")\n",
        "\n",
        "        down2, p2 = self.down_conv_2(p1)\n",
        "        #print(f\"Shape after doubl_conv_2_only : {down2.shape}\")\n",
        "        #print(f\"Shape after down_conv_2: {p2.shape}\")\n",
        "\n",
        "        down3, p3 = self.down_conv_3(p2)\n",
        "        #print(f\"Shape after doubl_conv_3_only : {down3.shape}\")\n",
        "        #print(f\"Shape after down_conv_3 : {p3.shape}\")\n",
        "\n",
        "        down4, p4 = self.down_conv_4(p3)\n",
        "        #print(f\"Shape after doubl_conv_4_only : {down4.shape}\")\n",
        "        #print(f\"Shape after down_conv_4 : {p4.shape}\")\n",
        "\n",
        "        b = self.bottleneck(p4)\n",
        "        #print(f\"Shape after bottleneck : {b.shape}\")\n",
        "\n",
        "        up_1 = self.up_conv_1(b, down4)\n",
        "        #print(f\"Shape after up_1 : {up_1.shape}\")\n",
        "        up_2 = self.up_conv_2(up_1,down3)\n",
        "        #print(f\"Shape after up_2 : {up_2.shape}\")\n",
        "        up_3 = self.up_conv_3(up_2, down2)\n",
        "        #print(f\"Shape after up_3 : {up_3.shape}\")\n",
        "        up_4 = self.up_conv_4(up_3, down1)\n",
        "        #print(f\"Shape after up_4 : {up_4.shape}\")\n",
        "\n",
        "        op = self.out(up_4)\n",
        "        #print(f\"Shape of output : {op.shape}\")\n",
        "\n",
        "        return op\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c0QhwWQSOcEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hF6iW-bpOL2v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "models = [\"/content/drive/MyDrive/major_proj/trained_models/unetwithbce.pth\",\n",
        "          \"/content/drive/MyDrive/major_proj/trained_models/unetwithdiceloss.pth\",\n",
        "          \"/content/drive/MyDrive/major_proj/trained_models/unet_aug_dice.pth\",\n",
        "          '/content/drive/MyDrive/major_proj/trained_models/unetauganddiceandbce.pth',\n",
        "          '/content/drive/MyDrive/major_proj/trained_models/unetauganddicelovasz.pth'\n",
        "          ]\n",
        "\n",
        "def evaluate_model():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = UNet(4,1)\n",
        "\n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/major_proj/trained_models/unet_dice.pth',weights_only=True))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_dataset = hrgldd_dataset(\n",
        "        data_testX,\n",
        "        data_testY\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=16,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    total_loss = 0.0\n",
        "    dice_scores = []\n",
        "    iou_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "    accuracy_scores = []\n",
        "\n",
        "    # Evaluation loop\n",
        "    with torch.no_grad():  # No gradients needed for evaluation\n",
        "        for i, data in enumerate(test_loader):\n",
        "            inputs, targets = data\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = torch.sigmoid(model(inputs))\n",
        "\n",
        "            loss = dice_loss(outputs, targets)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            targets = targets.float()\n",
        "\n",
        "            # Calculate metrics\n",
        "            # dice = calculate_dice(predicted, targets)\n",
        "            # dice_scores.append(dice.item())\n",
        "\n",
        "            # iou = calculate_iou(predicted, targets)\n",
        "            # iou_scores.append(iou.item())\n",
        "\n",
        "            precision = calculate_precision(predicted, targets)\n",
        "            precision_scores.append(precision.item())\n",
        "\n",
        "            recall = calculate_recall(predicted, targets)\n",
        "            recall_scores.append(recall.item())\n",
        "\n",
        "            f1 = calculate_f1(precision, recall)\n",
        "            f1_scores.append(f1.item())\n",
        "\n",
        "            accuracy = calculate_accuracy(predicted, targets)\n",
        "            accuracy_scores.append(accuracy.item())\n",
        "\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    avg_dice = sum(dice_scores) / len(dice_scores)\n",
        "    avg_iou = sum(iou_scores) / len(iou_scores)\n",
        "    avg_precision = sum(precision_scores) / len(precision_scores)\n",
        "    avg_recall = sum(recall_scores) / len(recall_scores)\n",
        "    avg_f1 = sum(f1_scores) / len(f1_scores)\n",
        "    avg_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "\n",
        "    print(f\"Test Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Average Dice Score: {avg_dice:.4f}\")\n",
        "    print(f\"Average IoU: {avg_iou:.4f}\")\n",
        "    print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "    print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "    print(f\"Average F1 Score: {avg_f1:.4f}\")\n",
        "    print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'loss': avg_loss,\n",
        "        'dice': avg_dice,\n",
        "        'iou': avg_iou,\n",
        "        'precision': avg_precision,\n",
        "        'recall': avg_recall,\n",
        "        'f1': avg_f1,\n",
        "        'accuracy': avg_accuracy\n",
        "    }\n",
        "\n",
        "def calculate_precision(pred, target):\n",
        "    smooth = 1.0\n",
        "    true_positives = torch.sum(pred * target)\n",
        "    predicted_positives = torch.sum(pred)\n",
        "    return (true_positives + smooth) / (predicted_positives + smooth)\n",
        "\n",
        "def calculate_recall(pred, target):\n",
        "    smooth = 1.0\n",
        "    true_positives = torch.sum(pred * target)\n",
        "    actual_positives = torch.sum(target)\n",
        "    return (true_positives + smooth) / (actual_positives + smooth)\n",
        "\n",
        "def calculate_f1(precision, recall):\n",
        "    # Can also be calculated directly, but using precision and recall for clarity\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "def calculate_accuracy(pred, target):\n",
        "    smooth = 1.0\n",
        "    correct = torch.sum(pred == target)\n",
        "    total = torch.numel(pred)\n",
        "    return (correct + smooth) / (total + smooth)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = evaluate_model()"
      ],
      "metadata": {
        "id": "BwPdbZS2t4FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def visualize_comparison(model, test_loader, device, num_images=10):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader):\n",
        "            inputs, targets = data\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = torch.sigmoid(model(inputs))  # Apply sigmoid to get probabilities\n",
        "\n",
        "            predicted = (outputs > 0.5).float()  # Threshold to get binary predictions\n",
        "\n",
        "            if i == 0:\n",
        "                for j in range(num_images):\n",
        "                    input_img = inputs[j].cpu().numpy()[0:3,:,:].transpose(1, 2, 0) # Convert to HWC format\n",
        "                    target_mask = targets[j].cpu().numpy().squeeze()  # Remove channel dimension for ground truth\n",
        "                    pred_mask = predicted[j].cpu().numpy().squeeze()  # Remove channel dimension for prediction\n",
        "\n",
        "                    # Plot original image, ground truth, and prediction\n",
        "                    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "                    axes[0].imshow(input_img)\n",
        "                    axes[0].set_title(\"Input Image\")\n",
        "                    axes[0].axis('off')\n",
        "\n",
        "                    axes[1].imshow(target_mask, cmap='gray')\n",
        "                    axes[1].set_title(\"Ground Truth\")\n",
        "                    axes[1].axis('off')\n",
        "\n",
        "                    axes[2].imshow(pred_mask, cmap='gray')\n",
        "                    axes[2].set_title(\"Predicted Mask\")\n",
        "                    axes[2].axis('off')\n",
        "\n",
        "                    plt.show()\n",
        "\n",
        "            # Break after visualizing the required number of images\n",
        "            if i >= num_images // len(test_loader):\n",
        "                break"
      ],
      "metadata": {
        "id": "qiymkyZt3TpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = hrgldd_dataset(\n",
        "        data_testX,\n",
        "        data_testY\n",
        "    )\n",
        "\n",
        "test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=16,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = UNet(4,1)\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/major_proj/trained_models/unet_dice.pth\", map_location=device))\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "visualize_comparison(model, test_loader, device, num_images=10)"
      ],
      "metadata": {
        "id": "_3atYfqT-TCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D5tRnOTD_a5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Newer Code"
      ],
      "metadata": {
        "id": "qAm3wtHVYQNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "idx = 2\n",
        "\n",
        "# Define function to calculate metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    iou = jaccard_score(y_true.flatten(), y_pred.flatten(), average='binary')\n",
        "    dice = 2 * np.sum(y_true.flatten() * y_pred.flatten()) / (np.sum(y_true.flatten()) + np.sum(y_pred.flatten()))\n",
        "    precision = precision_score(y_true.flatten(), y_pred.flatten(),zero_division = 0)\n",
        "    recall = recall_score(y_true.flatten(), y_pred.flatten())\n",
        "    f1 = f1_score(y_true.flatten(), y_pred.flatten())\n",
        "    return iou, dice, precision, recall, f1\n",
        "\n",
        "def plot_comparison(images, gt, predictions, model_names):\n",
        "    # Create a new layout with len(model_names) + 2 columns:\n",
        "    # The first column is for the RGB image, the second for ground truth,\n",
        "    # and the remaining columns for model predictions\n",
        "    fig, axes = plt.subplots(3, len(model_names) + 2, figsize=(20, 12))\n",
        "\n",
        "    for i in range(3):\n",
        "        # Plot the RGB Image (BGR to RGB conversion)\n",
        "        image = images[i][:3, :, :]  # Take the first 3 channels (BGR)\n",
        "        image = image[[2, 1, 0], :, :]  # Swap channels from BGR to RGB\n",
        "        image = image.permute(1, 2, 0).cpu().numpy()  # Convert to HxWxC format\n",
        "        axes[i, 0].imshow(image)\n",
        "        axes[i, 0].set_title(f\"RGB Image {i+1}\")\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        # Plot the ground truth in the second column\n",
        "        ground_truth = gt[i].squeeze()  # Assuming ground truth is a single-channel image\n",
        "        axes[i, 1].imshow(ground_truth, cmap='gray')\n",
        "        axes[i, 1].set_title(\"Ground Truth\")\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        # Plot the predictions for each model in subsequent columns\n",
        "        for j, model_name in enumerate(model_names):\n",
        "            # Instead of plotting prediction[i], match predictions to the corresponding index\n",
        "            prediction = predictions[model_name][i].squeeze()  # Using i to match the same index as images\n",
        "            if isinstance(prediction, np.ndarray):  # If it's already a NumPy array\n",
        "                axes[i, j+2].imshow(prediction, cmap='gray')\n",
        "            else:  # If it's a PyTorch tensor, convert to NumPy\n",
        "                axes[i, j+2].imshow(prediction.cpu().numpy(), cmap='gray')\n",
        "            axes[i, j+2].set_title(f\"{model_name}\")\n",
        "            axes[i, j+2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load your test dataset (use DataLoader for batch processing)\n",
        "test_dataset = hrgldd_dataset(data_testX, data_testY)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "weights = [\n",
        "    \"/content/drive/MyDrive/major_proj/trained_models/unetwithbce.pth\",\n",
        "    \"/content/drive/MyDrive/major_proj/trained_models/unetwithdiceloss.pth\",\n",
        "    \"/content/drive/MyDrive/major_proj/trained_models/unet_aug_dice.pth\",\n",
        "    '/content/drive/MyDrive/major_proj/trained_models/unetauganddiceandbce.pth',\n",
        "    '/content/drive/MyDrive/major_proj/trained_models/unetauganddicelovasz.pth'\n",
        "]\n",
        "\n",
        "model_names = [\"UNet + BCE\", \"UNet + Dice\", \"UNet + Aug + Dice\", \"UNet + Aug + Dice + BCE\", \"UNet + Aug + Dice + Lovasz\"]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize a dictionary for metrics and predictions\n",
        "metrics = {model_name: {\"IoU\": [], \"Dice\": [], \"Precision\": [], \"Recall\": [], \"F1\": []} for model_name in model_names}\n",
        "predictions = {model_name: [] for model_name in model_names}\n",
        "\n",
        "for model_name, weight_path in zip(model_names, weights):\n",
        "\n",
        "    model = UNet(4,1).to(device)\n",
        "\n",
        "    model.load_state_dict(torch.load(weight_path, map_location = device, weights_only=True))\n",
        "    model.eval()\n",
        "\n",
        "    # Iterate through the test set\n",
        "    for images, masks in test_loader:  # Replace this with your dataset's DataLoader\n",
        "\n",
        "        images = images.float().to(device)  # Assuming GPU usage; change to .cpu() if using CPU\n",
        "\n",
        "        # Forward pass\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "            predicted_mask = torch.sigmoid(outputs).cpu().numpy() > 0.5  # Thresholding\n",
        "\n",
        "        # Calculate metrics\n",
        "        iou, dice, precision, recall, f1 = calculate_metrics(masks.cpu().numpy(), predicted_mask)\n",
        "\n",
        "        # # Store metrics\n",
        "        metrics[model_name][\"IoU\"].append(iou)\n",
        "        metrics[model_name][\"Dice\"].append(dice)\n",
        "        metrics[model_name][\"Precision\"].append(precision)\n",
        "        metrics[model_name][\"Recall\"].append(recall)\n",
        "        metrics[model_name][\"F1\"].append(f1)\n",
        "\n",
        "        # Store predictions for comparison plot\n",
        "        predictions[model_name].append(predicted_mask)\n",
        "\n",
        "    # Print out average metrics for the model\n",
        "    avg_metrics = {metric: np.mean(values) for metric, values in metrics[model_name].items()}\n",
        "    print(f\"Metrics for {model_name}: {avg_metrics}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7DPn_3f5YUBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_images = [test_dataset[i][0] for i in range(5,8)]  #  3 images\n",
        "example_masks = [test_dataset[i][1] for i in range(5,8)]  # 3 masks"
      ],
      "metadata": {
        "id": "RVcaQ7rvs8rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_comparison(example_images, example_masks, predictions, model_names, 5)"
      ],
      "metadata": {
        "id": "FIh7soKOs3Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Plot comparison for the 3 example images\n"
      ],
      "metadata": {
        "id": "q2zID2sUmejw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random_indices = random.sample(range(len(test_dataset)), 3)\n",
        "\n",
        "example_images = [test_dataset[i][0] for i in random_indices]\n",
        "example_masks = [test_dataset[i][1] for i in random_indices]\n",
        "\n",
        "# Plot comparison for the 3 example images\n",
        "plot_comparison(example_images, example_masks, predictions, model_names)"
      ],
      "metadata": {
        "id": "TMW5vAvpaBJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Select 3 random indices for the images to compare\n",
        "random_indices = random.sample(range(len(test_dataset)), 3)\n",
        "\n",
        "example_images = [test_dataset[i][0] for i in random_indices]\n",
        "example_masks = [test_dataset[i][1] for i in random_indices]\n",
        "\n",
        "# Define function to calculate metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    iou = jaccard_score(y_true.flatten(), y_pred.flatten(), average='binary')\n",
        "    dice = 2 * np.sum(y_true.flatten() * y_pred.flatten()) / (np.sum(y_true.flatten()) + np.sum(y_pred.flatten()))\n",
        "    precision = precision_score(y_true.flatten(), y_pred.flatten(), zero_division=0)\n",
        "    recall = recall_score(y_true.flatten(), y_pred.flatten())\n",
        "    f1 = f1_score(y_true.flatten(), y_pred.flatten())\n",
        "    return iou, dice, precision, recall, f1\n",
        "\n",
        "def plot_comparison(images, gt, predictions, model_names):\n",
        "    # Create a new layout with len(model_names) + 2 columns:\n",
        "    # The first column is for the RGB image, the second for ground truth,\n",
        "    # and the remaining columns for model predictions\n",
        "    fig, axes = plt.subplots(3, len(model_names) + 2, figsize=(20, 12))\n",
        "\n",
        "    for i in range(3):\n",
        "        # Plot the RGB Image (BGR to RGB conversion)\n",
        "        image = images[i][:3, :, :]  # Take the first 3 channels (BGR)\n",
        "        image = image[[2, 1, 0], :, :]  # Swap channels from BGR to RGB\n",
        "        image = image.permute(1, 2, 0).cpu().numpy()  # Convert to HxWxC format\n",
        "        axes[i, 0].imshow(image)\n",
        "        axes[i, 0].set_title(f\"RGB Image {i+1}\")\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        # Plot the ground truth in the second column\n",
        "        ground_truth = gt[i].squeeze()  # Assuming ground truth is a single-channel image\n",
        "        axes[i, 1].imshow(ground_truth, cmap='gray')\n",
        "        axes[i, 1].set_title(\"Ground Truth\")\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        # Plot the predictions for each model in subsequent columns\n",
        "        for j, model_name in enumerate(model_names):\n",
        "            prediction = predictions[model_name][i].squeeze()\n",
        "            if isinstance(prediction, np.ndarray):  # If it's already a NumPy array\n",
        "                axes[i, j+2].imshow(prediction, cmap='gray')\n",
        "            else:  # If it's a PyTorch tensor, convert to NumPy\n",
        "                axes[i, j+2].imshow(prediction.cpu().numpy(), cmap='gray')\n",
        "            axes[i, j+2].set_title(f\"{model_name}\")\n",
        "            axes[i, j+2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Load your test dataset (use DataLoader for batch processing)\n",
        "test_dataset = hrgldd_dataset(data_testX, data_testY)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "weights = [\n",
        "    \"/content/drive/MyDrive/major_proj/trained_models/unetwithbce.pth\",\n",
        "    \"/content/drive/MyDrive/major_proj/trained_models/unetwithdiceloss.pth\",\n",
        "    \"/content/drive/MyDrive/major_proj/trained_models/unet_aug_dice.pth\",\n",
        "    '/content/drive/MyDrive/major_proj/trained_models/unetauganddiceandbce.pth',\n",
        "    '/content/drive/MyDrive/major_proj/trained_models/unetauganddicelovasz.pth'\n",
        "]\n",
        "\n",
        "model_names = [\"UNet + BCE\", \"UNet + Dice\", \"UNet + Aug + Dice\", \"UNet + Aug + Dice + BCE\", \"UNet + Aug + Dice + Lovasz\"]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize a dictionary for metrics and predictions (only for selected images)\n",
        "predictions = {model_name: [] for model_name in model_names}\n",
        "\n",
        "for model_name, weight_path in zip(model_names, weights):\n",
        "    model = UNet(4, 1).to(device)\n",
        "    model.load_state_dict(torch.load(weight_path, map_location=device, weights_only=True))\n",
        "    model.eval()\n",
        "\n",
        "    # Collect predictions for the specific random images\n",
        "    for i, (images, masks) in enumerate(test_loader):\n",
        "        images = images.float().to(device)  # Assuming GPU usage; change to .cpu() if using CPU\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "            predicted_mask = torch.sigmoid(outputs).cpu().numpy() > 0.5  # Thresholding\n",
        "\n",
        "            if i in random_indices:\n",
        "                # Store the predictions for the randomly selected images\n",
        "                for j, model_name in enumerate(model_names):\n",
        "                    predictions[model_name].append(predicted_mask)\n",
        "\n",
        "# Plot the comparison of RGB images, ground truth, and model predictions\n",
        "plot_comparison(example_images, example_masks, predictions, model_names)\n"
      ],
      "metadata": {
        "id": "yFn6h8opZS-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def plot_comparison(images, gt, predictions, model_names, index):\n",
        "    # Check if the index is valid\n",
        "    if index < 0 or index >= len(images):\n",
        "        raise ValueError(f\"Index {index} is out of range. Please enter an index between 0 and {len(images)-1}.\")\n",
        "\n",
        "    # Create a new layout with len(model_names) + 2 columns:\n",
        "    fig, axes = plt.subplots(1, len(model_names) + 2, figsize=(20, 6))\n",
        "\n",
        "    # Plot the RGB Image (BGR to RGB conversion)\n",
        "    image = images[index][:3, :, :]  # Take the first 3 channels (BGR)\n",
        "    image = image[[2, 1, 0], :, :]  # Swap channels from BGR to RGB\n",
        "    image = image.permute(1, 2, 0).cpu().numpy()  # Convert to HxWxC format\n",
        "    axes[0].imshow(image)\n",
        "    axes[0].set_title(f\"RGB Image {index+1}\")\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Plot the ground truth in the second column\n",
        "    ground_truth = gt[index].squeeze()  # Assuming ground truth is a single-channel image\n",
        "    axes[1].imshow(ground_truth, cmap='gray')\n",
        "    axes[1].set_title(\"Ground Truth\")\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Plot the predictions for each model in subsequent columns\n",
        "    for j, model_name in enumerate(model_names):\n",
        "        prediction = predictions[model_name][index].squeeze()\n",
        "        if isinstance(prediction, np.ndarray):  # If it's already a NumPy array\n",
        "            axes[j+2].imshow(prediction, cmap='gray')\n",
        "        else:  # If it's a PyTorch tensor, convert to NumPy\n",
        "            axes[j+2].imshow(prediction.cpu().numpy(), cmap='gray')\n",
        "        axes[j+2].set_title(f\"{model_name}\")\n",
        "        axes[j+2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Load your test dataset (use DataLoader for batch processing)\n",
        "test_dataset = hrgldd_dataset(data_testX, data_testY)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "weights = [\n",
        "    \"/content/drive/MyDrive/major_proj/trained_models/unetwithbce.pth\",\n",
        "    \"/content/drive/MyDrive/major_proj/trained_models/unetwithdiceloss.pth\",\n",
        "    \"/content/drive/MyDrive/major_proj/trained_models/unet_aug_dice.pth\",\n",
        "    '/content/drive/MyDrive/major_proj/trained_models/unetauganddiceandbce.pth',\n",
        "    '/content/drive/MyDrive/major_proj/trained_models/unetauganddicelovasz.pth'\n",
        "]\n",
        "\n",
        "model_names = [\"UNet + BCE\", \"UNet + Dice\", \"UNet + Aug + Dice\", \"UNet + Aug + Dice + BCE\", \"UNet + Aug + Dice + Lovasz\"]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize a dictionary for storing predictions\n",
        "predictions = {model_name: [] for model_name in model_names}\n",
        "\n",
        "# Load models and store predictions\n",
        "for model_name, weight_path in zip(model_names, weights):\n",
        "    model = UNet(4,1).to(device)\n",
        "    model.load_state_dict(torch.load(weight_path, map_location=device, weights_only=True))\n",
        "    model.eval()\n",
        "\n",
        "    # Iterate through the test set\n",
        "    for images, masks in test_loader:\n",
        "        images = images.float().to(device)  # Assuming GPU usage; change to .cpu() if using CPU\n",
        "\n",
        "        # Forward pass\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "            predicted_mask = torch.sigmoid(outputs).cpu().numpy() > 0.5  # Thresholding\n",
        "\n",
        "        # Store predictions for comparison plot\n",
        "        predictions[model_name].append(predicted_mask)\n",
        "\n",
        "# Check the length of example_images\n",
        "print(f\"Length of example_images: {len(example_images)}\")\n",
        "print(f\"Length of example_masks: {len(example_masks)}\")\n",
        "\n",
        "# Now you can input an index to plot the image, ground truth, and predictions\n",
        "index = 0  # Example index; replace this with the index of your choice\n",
        "plot_comparison(example_images, example_masks, predictions, model_names, index)\n"
      ],
      "metadata": {
        "id": "Le7chKHVqnmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def run_model_inference(test_dataset, start_index=0):\n",
        "    \"\"\"\n",
        "    Run inference on 3 consecutive images starting from the given index\n",
        "    and plot the results for all models.\n",
        "\n",
        "    Args:\n",
        "    - test_dataset: The test dataset\n",
        "    - start_index: Starting index for selecting images (default is 0)\n",
        "\n",
        "    Returns:\n",
        "    - Matplotlib figure with image comparisons\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    weights = [\n",
        "        \"/content/drive/MyDrive/major_proj/trained_models/unetwithbce.pth\",\n",
        "        \"/content/drive/MyDrive/major_proj/trained_models/unetwithdiceloss.pth\",\n",
        "        \"/content/drive/MyDrive/major_proj/trained_models/unet_aug_dice.pth\",\n",
        "        '/content/drive/MyDrive/major_proj/trained_models/unetauganddiceandbce.pth',\n",
        "        '/content/drive/MyDrive/major_proj/trained_models/unetauganddicelovasz.pth'\n",
        "    ]\n",
        "\n",
        "    model_names = [\n",
        "        \"UNet + BCE\",\n",
        "        \"UNet + Dice\",\n",
        "        \"UNet + Aug + Dice\",\n",
        "        \"UNet + Aug + Dice + BCE\",\n",
        "        \"UNet + Aug + Dice + Lovasz\"\n",
        "    ]\n",
        "\n",
        "    # Select 3 consecutive images starting from start_index\n",
        "    example_images = [test_dataset[start_index+i][0] for i in range(3)]\n",
        "    example_masks = [test_dataset[start_index+i][1] for i in range(3)]\n",
        "\n",
        "    # Initialize a dictionary for predictions\n",
        "    predictions = {model_name: [] for model_name in model_names}\n",
        "\n",
        "    # Run inference for each model\n",
        "    for model_name, weight_path in zip(model_names, weights):\n",
        "        # Initialize and load model\n",
        "        model = UNet(4, 1).to(device)\n",
        "        model.load_state_dict(torch.load(weight_path, map_location=device, weights_only=True))\n",
        "        model.eval()\n",
        "\n",
        "        # Run inference for selected images\n",
        "        for image in example_images:\n",
        "            # Prepare image for inference\n",
        "            input_image = image.unsqueeze(0).float().to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_image)\n",
        "                predicted_mask = torch.sigmoid(outputs).cpu().numpy() > 0.5  # Thresholding\n",
        "                predictions[model_name].append(predicted_mask[0])  # Remove batch dimension\n",
        "\n",
        "    # Create plot comparison\n",
        "    def plot_comparison(images, gt, predictions, model_names):\n",
        "        # Create a new layout with len(model_names) + 2 columns\n",
        "        fig, axes = plt.subplots(3, len(model_names) + 2, figsize=(20, 12))\n",
        "\n",
        "        for i in range(3):\n",
        "            # Plot the RGB Image (BGR to RGB conversion)\n",
        "            image = images[i][:3, :, :]  # Take the first 3 channels (BGR)\n",
        "            image = image[[2, 1, 0], :, :]  # Swap channels from BGR to RGB\n",
        "            image = image.permute(1, 2, 0).cpu().numpy()  # Convert to HxWxC format\n",
        "            axes[i, 0].imshow(image)\n",
        "            axes[i, 0].set_title(f\"RGB Image\")\n",
        "            axes[i, 0].axis('off')\n",
        "\n",
        "            # Plot the ground truth in the second column\n",
        "            ground_truth = gt[i].squeeze()  # Assuming ground truth is a single-channel image\n",
        "            axes[i, 1].imshow(ground_truth, cmap='gray')\n",
        "            axes[i, 1].set_title(\"Ground Truth\")\n",
        "            axes[i, 1].axis('off')\n",
        "\n",
        "            # Plot the predictions for each model in subsequent columns\n",
        "            for j, model_name in enumerate(model_names):\n",
        "                prediction = predictions[model_name][i].squeeze()\n",
        "                if isinstance(prediction, np.ndarray):  # If it's already a NumPy array\n",
        "                    axes[i, j+2].imshow(prediction, cmap='gray')\n",
        "                else:  # If it's a PyTorch tensor, convert to NumPy\n",
        "                    axes[i, j+2].imshow(prediction.cpu().numpy(), cmap='gray')\n",
        "                axes[i, j+2].set_title(f\"{model_name}\")\n",
        "                axes[i, j+2].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        return fig\n",
        "\n",
        "    # Call the plot comparison function\n",
        "    return plot_comparison(example_images, example_masks, predictions, model_names)\n",
        "\n",
        "# Usage example:\n",
        "run_model_inference(test_dataset, start_index=55)"
      ],
      "metadata": {
        "id": "7qxN7Aybwf6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X4cbrYiRxuvE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}